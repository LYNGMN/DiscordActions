import xml.etree.ElementTree as ET
import requests
import re
import os
import time
import random
import logging
import json
import base64
import sqlite3
import sys
from urllib.parse import urlparse, parse_qs
from datetime import datetime, timedelta
from dateutil import parser
from dateutil.tz import gettz
from bs4 import BeautifulSoup

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
DISCORD_WEBHOOK_TOPIC = os.environ.get('DISCORD_WEBHOOK_TOPIC')
DISCORD_AVATAR_TOPIC = os.environ.get('DISCORD_AVATAR_TOPIC', '').strip()
DISCORD_USERNAME_TOPIC = os.environ.get('DISCORD_USERNAME_TOPIC', '').strip()
INITIALIZE_TOPIC = os.environ.get('INITIALIZE_MODE_TOPIC', 'false').lower() == 'true'
ADVANCED_FILTER_TOPIC = os.environ.get('ADVANCED_FILTER_TOPIC', '')
DATE_FILTER_TOPIC = os.environ.get('DATE_FILTER_TOPIC', '')
ORIGIN_LINK_TOPIC = os.getenv('ORIGIN_LINK_TOPIC', '').lower()
ORIGIN_LINK_TOPIC = ORIGIN_LINK_TOPIC not in ['false', 'f', '0', 'no', 'n']
TOPIC_MODE = os.environ.get('TOPIC_MODE', 'false').lower() == 'true'
TOPIC_KEYWORD = os.environ.get('TOPIC_KEYWORD', '')
TOPIC_PARAMS = os.environ.get('TOPIC_PARAMS', '?hl=ko&gl=KR&ceid=KR%3Ako')
RSS_URL_TOPIC = os.environ.get('RSS_URL_TOPIC', '')

# DB ì„¤ì •
DB_PATH = 'google_news_topic.db'

# í† í”½ ID ë§¤í•‘
TOPIC_MAP = {
    # í—¤ë“œë¼ì¸ ë‰´ìŠ¤
    "headlines": {
        "ko-KR": ("í—¤ë“œë¼ì¸", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRFZxYUdjU0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("Headlines", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRFZxYUdjU0FtdHZHZ0pMVWlnQVAB")
    },
    "korea": {
        "ko-KR": ("ëŒ€í•œë¯¼êµ­", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFp4WkRNU0FtdHZLQUFQAQ")
    },
    "us": {
        "en-US": ("U.S.", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRGxqTjNjd0VnSmxiaWdBUAE")
    },
    "world": {
        "ko-KR": ("ì„¸ê³„", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx1YlY4U0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("World", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx1YlY4U0FtVnVHZ0pWVXlnQVAB")
    },
    "politics": {
        "ko-KR": ("ì •ì¹˜", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZ4ZERBU0FtdHZLQUFQAQ"),
        "en-US": ("Politics", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZ4ZERBU0FtVnVLQUFQAQ")
    },
    
    # ì—°ì˜ˆ ë‰´ìŠ¤
    "entertainment": {
        "ko-KR": ("ì—”í„°í…Œì¸ë¨¼íŠ¸", "CAAqJggKIiBDQkFTRWdvSUwyMHZNREpxYW5RU0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("Entertainment", "CAAqJggKIiBDQkFTRWdvSUwyMHZNREpxYW5RU0FtVnVHZ0pWVXlnQVAB")
    },
    "celebrity": {
        "ko-KR": ("ì—°ì˜ˆ", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZ5Wm5vU0FtdHZLQUFQAQ"),
        "en-US": ("Celebrities", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZ5Wm5vU0FtVnVLQUFQAQ")
    },
    "tv": {
        "ko-KR": ("TV", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGRqTlRJU0FtdHZLQUFQAQ"),
        "en-US": ("TV", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGRqTlRJU0FtVnVLQUFQAQ")
    },
    "music": {
        "ko-KR": ("ìŒì•…", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFJ5YkdZU0FtdHZLQUFQAQ"),
        "en-US": ("Music", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFJ5YkdZU0FtVnVLQUFQAQ")
    },
    "movies": {
        "ko-KR": ("ì˜í™”", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREoyZUc0U0FtdHZLQUFQAQ"),
        "en-US": ("Movies", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREoyZUc0U0FtVnVLQUFQAQ")
    },
    "theater": {
        "ko-KR": ("ì—°ê·¹", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRE54YzJSd2F4SUNhMjhvQUFQAQ"),
        "en-US": ("Theater", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRE54YzJSd2F4SUNaVzRvQUFQAQ")
    },
    
    # ìŠ¤í¬ì¸  ë‰´ìŠ¤
    "sports": {
        "ko-KR": ("ìŠ¤í¬ì¸ ", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp1ZEdvU0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("Sports", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp1ZEdvU0FtVnVHZ0pWVXlnQVAB")
    },
    "soccer": {
        "ko-KR": ("ì¶•êµ¬", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREoyZURRU0FtdHZLQUFQAQ"),
        "en-US": ("Soccer", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREoyZURRU0FtVnVLQUFQAQ")
    },
    "cycling": {
        "ko-KR": ("ìì „ê±°", "PLACEHOLDER_ID_CYCLING"),
        "en-US": ("Cycling", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZ6WjJ3U0FtVnVLQUFQAQ")
    },
    "motorsports": {
        "ko-KR": ("ëª¨í„°ìŠ¤í¬ì¸ ", "PLACEHOLDER_ID_MOTORSPORTS"),
        "en-US": ("Motor sports", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRFF4TUhSMGFCSUNaVzRvQUFQAQ")
    },
    "tennis": {
        "ko-KR": ("í…Œë‹ˆìŠ¤", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGRpY3pBU0FtdHZLQUFQAQ"),
        "en-US": ("Tennis", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGRpY3pBU0FtVnVLQUFQAQ")
    },
    "martial_arts": {
        "ko-KR": ("ê²©íˆ¬ê¸°", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRFZyWXpJNUVnSnJieWdBUAE"),
        "en-US": ("Combat sports", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRFZyWXpJNUVnSmxiaWdBUAE")
    },
    "basketball": {
        "ko-KR": ("ë†êµ¬", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREU0ZHpnU0FtdHZLQUFQAQ"),
        "en-US": ("Basketball", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREU0ZHpnU0FtVnVLQUFQAQ")
    },
    "baseball": {
        "ko-KR": ("ì•¼êµ¬", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREU0YW5vU0FtdHZLQUFQAQ"),
        "en-US": ("Baseball", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREU0YW5vU0FtVnVLQUFQAQ")
    },
    "american_football": {
        "ko-KR": ("ë¯¸ì‹ì¶•êµ¬", "PLACEHOLDER_ID_AMERICAN_FOOTBALL"),
        "en-US": ("Football", "CAAqIAgKIhpDQkFTRFFvSEwyMHZNR3B0WHhJQ1pXNG9BQVAB")
    },
    "sports_betting": {
        "ko-KR": ("ìŠ¤í¬ì¸  ë² íŒ…", "PLACEHOLDER_ID_SPORTS_BETTING"),
        "en-US": ("Sports betting", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRFIwTXpsa0VnSmxiaWdBUAE")
    },
    "water_sports": {
        "ko-KR": ("ìˆ˜ìƒ ìŠ¤í¬ì¸ ", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREptYUdSbUVnSnJieWdBUAE"),
        "en-US": ("Water sports", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREptYUdSbUVnSmxiaWdBUAE")
    },
    "hockey": {
        "ko-KR": ("í•˜í‚¤", "PLACEHOLDER_ID_HOCKEY"),
        "en-US": ("Hockey", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE4wYlhJU0FtVnVLQUFQAQ")
    },
    "golf": {
        "ko-KR": ("ê³¨í”„", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE0zYUhvU0FtdHZLQUFQAQ"),
        "en-US": ("Golf", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE0zYUhvU0FtVnVLQUFQAQ")
    },
    "cricket": {
        "ko-KR": ("í¬ë¦¬ì¼“", "PLACEHOLDER_ID_CRICKET"),
        "en-US": ("Cricket", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGw0Y0Y4U0FtVnVLQUFQAQ")
    },
    "rugby": {
        "ko-KR": ("ëŸ­ë¹„", "PLACEHOLDER_ID_RUGBY"),
        "en-US": ("Rugby", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFppY2pnU0FtVnVLQUFQAQ")
    },
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ë‰´ìŠ¤
    "business": {
        "ko-KR": ("ë¹„ì¦ˆë‹ˆìŠ¤", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("Business", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtVnVHZ0pWVXlnQVAB")
    },
    "economy": {
        "ko-KR": ("ê²½ì œ", "CAAqIggKIhxDQkFTRHdvSkwyMHZNR2RtY0hNekVnSnJieWdBUAE"),
        "en-US": ("Economy", "CAAqIggKIhxDQkFTRHdvSkwyMHZNR2RtY0hNekVnSmxiaWdBUAE")
    },
    "personal_finance": {
        "ko-KR": ("ê°œì¸ ê¸ˆìœµ", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREY1Tm1OeEVnSnJieWdBUAE"),
        "en-US": ("Personal Finance", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREY1Tm1OeEVnSmxiaWdBUAE")
    },
    "finance": {
        "ko-KR": ("ê¸ˆìœµ", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREpmTjNRU0FtdHZLQUFQAQ"),
        "en-US": ("Finance", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREpmTjNRU0FtVnVLQUFQAQ")
    },
    "digital_currency": {
        "ko-KR": ("ë””ì§€í„¸ í†µí™”", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNSEk0YkhsM054SUNhMjhvQUFQAQ"),
        "en-US": ("Digital currencies", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNSEk0YkhsM054SUNaVzRvQUFQAQ")
    },
    
    # ê¸°ìˆ  ë‰´ìŠ¤
    "technology": {
        "ko-KR": ("ê³¼í•™/ê¸°ìˆ ", "CAAqKAgKIiJDQkFTRXdvSkwyMHZNR1ptZHpWbUVnSnJieG9DUzFJb0FBUAE"),
        "en-US": ("Technology", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtVnVHZ0pWVXlnQVAB")
    },
    "mobile": {
        "ko-KR": ("ëª¨ë°”ì¼", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFV3YXpnU0FtdHZLQUFQAQ"),
        "en-US": ("Mobile", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFV3YXpnU0FtVnVLQUFQAQ")
    },
    "energy": {
        "ko-KR": ("ì—ë„ˆì§€", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREp0YlY4U0FtdHZLQUFQAQ"),
        "en-US": ("Energy", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREp0YlY4U0FtVnVLQUFQAQ")
    },
    "games": {
        "ko-KR": ("ê²Œì„", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZ0ZHpFU0FtdHZLQUFQAQ"),
        "en-US": ("Games", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZ0ZHpFU0FtVnVLQUFQAQ")
    },
    "internet_security": {
        "ko-KR": ("ì¸í„°ë„· ë³´ì•ˆ", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRE5xWm01NEVnSnJieWdBUAE"),
        "en-US": ("Internet security", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRE5xWm01NEVnSmxiaWdBUAE")
    },
    "electronics": {
        "ko-KR": ("ì „ìê¸°ê¸°", "PLACEHOLDER_ID_ELECTRONICS"),
        "en-US": ("Electronics", "PLACEHOLDER_ID_ELECTRONICS")
    },
    "virtual_reality": {
        "ko-KR": ("ê°€ìƒ í˜„ì‹¤", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGRmYm5rU0FtdHZLQUFQAQ"),
        "en-US": ("Virtual Reality", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRGRmYm5rU0FtVnVLQUFQAQ")
    },
    "robotics": {
        "ko-KR": ("ë¡œë´‡", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNREp3TUhRMVpoSUNhMjhvQUFQAQ"),
        "en-US": ("Robotics", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNREp3TUhRMVpoSUNaVzRvQUFQAQ")
    },
    
    # ê±´ê°• ë‰´ìŠ¤
    "health": {
        "ko-KR": ("ê±´ê°•", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNR3QwTlRFU0FtdHZLQUFQAQ"),
        "en-US": ("Health", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNR3QwTlRFU0FtVnVLQUFQAQ")
    },
    "nutrition": {
        "ko-KR": ("ì˜ì–‘", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZrYW1NU0FtdHZLQUFQAQ"),
        "en-US": ("Nutrition", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZrYW1NU0FtVnVLQUFQAQ")
    },
    "public_health": {
        "ko-KR": ("ê³µê³µë³´ê±´í•™", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREpqYlRZeEVnSnJieWdBUAE"),
        "en-US": ("Public health", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREpqYlRZeEVnSmxiaWdBUAE")
    },
    "mental_health": {
        "ko-KR": ("ì •ì‹  ê±´ê°•", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRE40TmpsbkVnSnJieWdBUAE"),
        "en-US": ("Mental health", "CAAqIggKIhxDQkFTRHdvSkwyMHZNRE40TmpsbkVnSmxiaWdBUAE")
    },
    "medicine": {
        "ko-KR": ("ì˜ì•½í’ˆ", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFJ6YURNU0FtdHZLQUFQAQ"),
        "en-US": ("Medicine", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFJ6YURNU0FtVnVLQUFQAQ")
    },
    
    # ê³¼í•™ ë‰´ìŠ¤
    "science": {
        "ko-KR": ("ê³¼í•™", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp0Y1RjU0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("Science", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp0Y1RjU0FtVnVHZ0pWVXlnQVAB")
    },
    "space": {
        "ko-KR": ("ìš°ì£¼", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREU0TXpOM0VnSnJieWdBUAE"),
        "en-US": ("Space", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREU0TXpOM0VnSmxiaWdBUAE")
    },
    "wildlife": {
        "ko-KR": ("ì•¼ìƒë™ë¬¼", "CAAqJAgKIh5DQkFTRUFvS0wyY3ZNVE5pWWw5MGN4SUNhMjhvQUFQAQ"),
        "en-US": ("Wildlife", "CAAqJAgKIh5DQkFTRUFvS0wyY3ZNVE5pWWw5MGN4SUNaVzRvQUFQAQ")
    },
    "environment": {
        "ko-KR": ("í™˜ê²½", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREp3ZVRBNUVnSnJieWdBUAE"),
        "en-US": ("Environment", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREp3ZVRBNUVnSmxiaWdBUAE")
    },
    "neuroscience": {
        "ko-KR": ("ì‹ ê²½ê³¼í•™", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZpTm1NU0FtdHZLQUFQAQ"),
        "en-US": ("Neuroscience", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZpTm1NU0FtVnVLQUFQAQ")
    },
    "physics": {
        "ko-KR": ("ë¬¼ë¦¬í•™", "PLACEHOLDER_ID_PHYSICS"),
        "en-US": ("Physics", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZ4YW5RU0FtVnVLQUFQAQ")
    },
    "geography": {
        "ko-KR": ("ì§€ë¦¬í•™", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE0yYUhZU0FtdHZLQUFQAQ"),
        "en-US": ("Geology", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE0yYUhZU0FtVnVLQUFQAQ")
    },
    "paleontology": {
        "ko-KR": ("ê³ ìƒë¬¼í•™", "PLACEHOLDER_ID_PALEONTOLOGY"),
        "en-US": ("Paleontology", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFZ5YW13U0FtVnVLQUFQAQ")
    },
    "social_science": {
        "ko-KR": ("ì‚¬íšŒ ê³¼í•™", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFp1Tm5BU0FtdHZLQUFQAQ"),
        "en-US": ("Social sciences", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRFp1Tm5BU0FtVnVLQUFQAQ")
    },
    
    # êµìœ¡ ë‰´ìŠ¤
    "education": {
        "ko-KR": ("êµìœ¡", "CAAqJQgKIh9DQkFTRVFvTEwyY3ZNVEl4Y0Raa09UQVNBbXR2S0FBUAE"),
        "en-US": ("Education", "CAAqJQgKIh9DQkFTRVFvTEwyY3ZNVEl4Y0Raa09UQVNBbVZ1S0FBUAE")
    },
    "job_market": {
        "ko-KR": ("ì±„ìš©ì •ë³´", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRFF4TVRWME1oSUNhMjhvQUFQAQ"),
        "en-US": ("Jobs", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRFF4TVRWME1oSUNaVzRvQUFQAQ")
    },
    "online_education": {
        "ko-KR": ("ì˜¨ë¼ì¸ êµìœ¡", "PLACEHOLDER_ID_ONLINE_EDUCATION"),
        "en-US": ("Higher education", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE55TlRVU0FtVnVLQUFQAQ")
    },
    "higher_education": {
        "ko-KR": ("ê³ ë“±êµìœ¡", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE55TlRVU0FtdHZLQUFQAQ"),
        "en-US": ("Higher education", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE55TlRVU0FtVnVLQUFQAQ")
    },
    
    # ë¼ì´í”„ìŠ¤íƒ€ì¼ ë‰´ìŠ¤
    "lifestyle": {
        "ko-KR": ("ë¼ì´í”„ìŠ¤íƒ€ì¼", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRE55YXpBU0FtdHZHZ0pMVWlnQVAB"),
        "en-US": ("Lifestyle", "CAAqJggKIiBDQkFTRWdvSUwyMHZNRE55YXpBU0FtVnVHZ0pMVWlnQVAB")
    },
    "automotive": {
        "ko-KR": ("ì°¨ëŸ‰", "CAAqIAgKIhpDQkFTRFFvSEwyMHZNR3MwYWhJQ2EyOG9BQVAB"),
        "en-US": ("Vehicles", "CAAqIAgKIhpDQkFTRFFvSEwyMHZNR3MwYWhJQ1pXNG9BQVAB")
    },
    "art_design": {
        "ko-KR": ("ì˜ˆìˆ /ë””ìì¸", "CAAqIAgKIhpDQkFTRFFvSEwyMHZNR3BxZHhJQ2EyOG9BQVAB"),
        "en-US": ("Arts & design", "CAAqIAgKIhpDQkFTRFFvSEwyMHZNR3BxZHhJQ1pXNG9BQVAB")
    },
    "beauty": {
        "ko-KR": ("ë¯¸ìš©", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZtTkRNU0FtdHZLQUFQAQ"),
        "en-US": ("Beauty", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREZtTkRNU0FtVnVLQUFQAQ")
    },
    "food": {
        "ko-KR": ("ìŒì‹", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREozWW0wU0FtdHZLQUFQAQ"),
        "en-US": ("Food", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNREozWW0wU0FtVnVLQUFQAQ")
    },
    "travel": {
        "ko-KR": ("ì—¬í–‰", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREUwWkhONEVnSnJieWdBUAE"),
        "en-US": ("Travel", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREUwWkhONEVnSmxiaWdBUAE")
    },
    "shopping": {
        "ko-KR": ("ì‡¼í•‘", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNR2hvWkdJU0FtdHZLQUFQAQ"),
        "en-US": ("Shopping", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNR2hvWkdJU0FtVnVLQUFQAQ")
    },
    "home": {
        "ko-KR": ("í™ˆ", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREZzTUcxM0VnSnJieWdBUAE"),
        "en-US": ("Home", "CAAqIggKIhxDQkFTRHdvSkwyMHZNREZzTUcxM0VnSmxiaWdBUAE")
    },
    "outdoor": {
        "ko-KR": ("ì•¼ì™¸ í™œë™", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRFZpTUc0M2F4SUNhMjhvQUFQAQ"),
        "en-US": ("Outdoors", "CAAqJAgKIh5DQkFTRUFvS0wyMHZNRFZpTUc0M2F4SUNaVzRvQUFQAQ")
    },
    "fashion": {
        "ko-KR": ("íŒ¨ì…˜", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE15ZEd3U0FtdHZLQUFQAQ"),
        "en-US": ("Fashion", "CAAqIQgKIhtDQkFTRGdvSUwyMHZNRE15ZEd3U0FtVnVLQUFQAQ")
    }
}

def get_news_prefix(lang):
    """ì–¸ì–´ì— ë”°ë¼ ë‰´ìŠ¤ ì ‘ë‘ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    news_prefix_map = {
        'bn': "Google à¦¸à¦‚à¦¬à¦¾à¦¦",
        'zh': "Google æ–°é—»",
        'en': "Google News",
        'id': "Google Berita",
        'iw': "Google ×—×“×©×•×ª",
        'ja': "Google ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        'ar': "Google Ø£Ø®Ø¨Ø§Ø±",
        'ms': "Google Berita",
        'ko': "Google ë‰´ìŠ¤",
        'th': "Google à¸‚à¹ˆà¸²à¸§",
        'tr': "Google Haberler",
        'vi': "Google Tin tá»©c",
        'ru': "Google ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
        'de': "Google Nachrichten",
        'fr': "Google ActualitÃ©s",
        'es': "Google Noticias",
        'it': "Google Notizie",
        'nl': "Google Nieuws",
        'no': "Google Nyheter",
        'pl': "Google WiadomoÅ›ci",
        'ro': "Google È˜tiri",
        'hu': "Google HÃ­rek",
        'cs': "Google ZprÃ¡vy",
        'fi': "Google Uutiset",
        'da': "Google Nyheder",
        'el': "Google Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚",
        'sv': "Google Nyheter",
        'pt': "Google NotÃ­cias",
        # ì¶”ê°€ ì–¸ì–´...
    }
    return news_prefix_map.get(lang, "Google News")

def check_env_variables():
    """í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    if not DISCORD_WEBHOOK_TOPIC:
        raise ValueError("í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: DISCORD_WEBHOOK_TOPIC")
    if TOPIC_MODE:
        if TOPIC_KEYWORD not in TOPIC_MAP:
            raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ í† í”½ í‚¤ì›Œë“œì…ë‹ˆë‹¤: {TOPIC_KEYWORD}")
        hl, gl, ceid = parse_topic_params(TOPIC_PARAMS)
        logging.info(f"í† í”½ ëª¨ë“œ í™œì„±í™”: {TOPIC_KEYWORD}, íŒŒë¼ë¯¸í„°: {TOPIC_PARAMS}")
    else:
        if not RSS_URL_TOPIC:
            raise ValueError("í† í”½ ëª¨ë“œê°€ ë¹„í™œì„±í™”ë˜ì—ˆì„ ë•ŒëŠ” RSS_URL_TOPICì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        hl, gl, ceid = parse_topic_params(RSS_URL_TOPIC)
        logging.info(f"ì¼ë°˜ ëª¨ë“œ í™œì„±í™”, RSS í”¼ë“œ URL: {RSS_URL_TOPIC}")
    
    return hl, gl, ceid

def init_db(reset=False):
    """ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        if reset:
            c.execute("DROP TABLE IF EXISTS news_items")
            logging.info("ê¸°ì¡´ news_items í…Œì´ë¸” ì‚­ì œ")
        c.execute('''CREATE TABLE IF NOT EXISTS news_items
                     (pub_date TEXT,
                      guid TEXT PRIMARY KEY,
                      title TEXT,
                      link TEXT,
                      topic TEXT,
                      related_news TEXT)''')
        logging.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

def is_guid_posted(guid):
    """ì£¼ì–´ì§„ GUIDê°€ ì´ë¯¸ ê²Œì‹œë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT 1 FROM news_items WHERE guid = ?", (guid,))
        return c.fetchone() is not None

def save_news_item(pub_date, guid, title, link, topic, related_news):
    """ë‰´ìŠ¤ í•­ëª©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # ê¸°ì¡´ í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        c.execute("PRAGMA table_info(news_items)")
        columns = [column[1] for column in c.fetchall()]
        
        # ê´€ë ¨ ë‰´ìŠ¤ í•­ëª© ìˆ˜ í™•ì¸
        related_news_count = len(json.loads(related_news))
        
        # í•„ìš”í•œ ì—´ ì¶”ê°€
        for i in range(related_news_count):
            title_col = f"related_title_{i+1}"
            press_col = f"related_press_{i+1}"
            link_col = f"related_link_{i+1}"
            
            if title_col not in columns:
                c.execute(f"ALTER TABLE news_items ADD COLUMN {title_col} TEXT")
            if press_col not in columns:
                c.execute(f"ALTER TABLE news_items ADD COLUMN {press_col} TEXT")
            if link_col not in columns:
                c.execute(f"ALTER TABLE news_items ADD COLUMN {link_col} TEXT")
        
        # ë°ì´í„° ì‚½ì…ì„ ìœ„í•œ SQL ì¿¼ë¦¬ ì¤€ë¹„
        columns = ["pub_date", "guid", "title", "link", "topic", "related_news"]
        values = [pub_date, guid, title, link, topic, related_news]
        
        related_news_items = json.loads(related_news)
        for i, item in enumerate(related_news_items):
            columns.extend([f"related_title_{i+1}", f"related_press_{i+1}", f"related_link_{i+1}"])
            values.extend([item['title'], item['press'], item['link']])
        
        placeholders = ", ".join(["?" for _ in values])
        columns_str = ", ".join(columns)
        
        c.execute(f"INSERT OR REPLACE INTO news_items ({columns_str}) VALUES ({placeholders})", values)
        
        logging.info(f"ìƒˆ ë‰´ìŠ¤ í•­ëª© ì €ì¥: {guid}")

def decode_base64_url_part(encoded_str):
    """base64ë¡œ ì¸ì½”ë”©ëœ ë¬¸ìì—´ì„ ë””ì½”ë”©"""
    base64_str = encoded_str + "=" * ((4 - len(encoded_str) % 4) % 4)
    try:
        decoded_bytes = base64.urlsafe_b64decode(base64_str)
        decoded_str = decoded_bytes.decode('latin1')
        return decoded_str
    except Exception as e:
        return f"ë””ì½”ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def extract_regular_url(decoded_str):
    """ë””ì½”ë”©ëœ ë¬¸ìì—´ì—ì„œ ì¼ë°˜ URL ì¶”ì¶œ"""
    parts = re.split(r'[^\x20-\x7E]+', decoded_str)
    url_pattern = r'(https?://[^\s]+)'
    for part in parts:
        match = re.search(url_pattern, part)
        if match:
            return match.group(0)
    return None

def extract_youtube_id(decoded_str):
    """ë””ì½”ë”©ëœ ë¬¸ìì—´ì—ì„œ ìœ íŠœë¸Œ ì˜ìƒ ID ì¶”ì¶œ"""
    pattern = r'\x08 "\x0b([\w-]{11})\x98\x01\x01'
    match = re.search(pattern, decoded_str)
    if match:
        return match.group(1)
    return None

def fetch_original_url_via_request(google_link, session, max_retries=5):
    """ì›ë³¸ ë§í¬ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ requestsë¥¼ ì‚¬ìš©"""
    wait_times = [5, 10, 30, 45, 60]
    for attempt in range(max_retries):
        try:
            response = session.get(google_link, allow_redirects=True, timeout=10)
            final_url = response.url
            logging.info(f"Requests ë°©ì‹ ì„±ê³µ - Google ë§í¬: {google_link}")
            logging.info(f"ìµœì¢… URL: {final_url}")
            return final_url
        except requests.RequestException as e:
            if attempt == max_retries - 1:
                logging.error(f"ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ì›ë³¸ ë§í¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
                return google_link
            wait_time = wait_times[min(attempt, len(wait_times) - 1)] + random.uniform(0, 5)
            logging.warning(f"ì‹œë„ {attempt + 1}/{max_retries}: ìš”ì²­ ì‹¤íŒ¨. {wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {str(e)}")
            time.sleep(wait_time)

    logging.error(f"ëª¨ë“  ë°©ë²• ì‹¤íŒ¨. ì›ë˜ì˜ Google ë§í¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {google_link}")
    return google_link

def decode_google_news_url(source_url):
    """Google ë‰´ìŠ¤ URLì„ ë””ì½”ë”©í•˜ì—¬ ì›ë³¸ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    url = urlparse(source_url)
    path = url.path.split('/')
    if url.hostname == "news.google.com" and len(path) > 1 and path[-2] == "articles":
        base64_str = path[-1]
        decoded_str = decode_base64_url_part(base64_str)
        
        # ì¼ë°˜ URL í˜•íƒœì¸ì§€ ë¨¼ì € í™•ì¸
        regular_url = extract_regular_url(decoded_str)
        if regular_url:
            logging.info(f"ì¼ë°˜ ë§í¬ ì¶”ì¶œ ì„±ê³µ: {source_url} -> {regular_url}")
            return regular_url
        
        # ì¼ë°˜ URLì´ ì•„ë‹Œ ê²½ìš° ìœ íŠœë¸Œ ID í˜•íƒœì¸ì§€ í™•ì¸
        youtube_id = extract_youtube_id(decoded_str)
        if youtube_id:
            youtube_url = f"https://www.youtube.com/watch?v={youtube_id}"
            logging.info(f"ìœ íŠœë¸Œ ë§í¬ ì¶”ì¶œ ì„±ê³µ: {source_url} -> {youtube_url}")
            return youtube_url
    
    logging.warning(f"Google ë‰´ìŠ¤ URL ë””ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ URL ë°˜í™˜: {source_url}")
    return source_url

def get_original_url(google_link, session, max_retries=5):
    """
    Google ë‰´ìŠ¤ ë§í¬ë¥¼ ì›ë³¸ URLë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
    ORIGIN_LINK_TOPIC ì„¤ì •ì— ë”°ë¼ ë™ì‘ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤:
    - ì„¤ì •í•˜ì§€ ì•Šì•˜ê±°ë‚˜ True: ì˜¤ë¦¬ì§€ë„ ë§í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - False: ì› ë§í¬(êµ¬ê¸€ ë§í¬)ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    logging.info(f"ORIGIN_LINK_TOPIC ê°’ í™•ì¸: {ORIGIN_LINK_TOPIC}")

    if ORIGIN_LINK_TOPIC:
        # ì˜¤ë¦¬ì§€ë„ ë§í¬ë¥¼ ê°€ì ¸ì˜¤ë ¤ê³  ì‹œë„
        original_url = decode_google_news_url(google_link)
        if original_url != google_link:
            return original_url

        # ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ requests ë°©ì‹ ì‹œë„
        retries = 0
        while retries < max_retries:
            try:
                response = session.get(google_link, allow_redirects=True)
                if response.status_code == 200:
                    return response.url
            except requests.RequestException as e:
                logging.error(f"ì›ë³¸ URL ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            retries += 1
        
        # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš° ì› ë§í¬ ë°˜í™˜
        logging.warning(f"ì˜¤ë¦¬ì§€ë„ ë§í¬ ì¶”ì¶œ ì‹¤íŒ¨, ì› ë§í¬ ì‚¬ìš©: {google_link}")
        return google_link
    else:
        # ORIGIN_LINK_TOPICê°€ Falseì¸ ê²½ìš° ì› ë§í¬ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
        logging.info(f"ORIGIN_LINK_TOPICê°€ False, ì› ë§í¬ ì‚¬ìš©: {google_link}")
        return google_link

def fetch_rss_feed(url):
    """RSS í”¼ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    response = requests.get(url)
    return response.content

def replace_brackets(text):
    """ëŒ€ê´„í˜¸ì™€ êº¾ì‡ ê´„í˜¸ë¥¼ ìœ ë‹ˆì½”ë“œ ë¬¸ìë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."""
    text = text.replace('[', 'ï¼»').replace(']', 'ï¼½')
    text = text.replace('<', 'ã€ˆ').replace('>', 'ã€‰')
    text = re.sub(r'(?<!\s)(?<!^)ï¼»', ' ï¼»', text)
    text = re.sub(r'ï¼½(?!\s)', 'ï¼½ ', text)
    text = re.sub(r'(?<!\s)(?<!^)ã€ˆ', ' ã€ˆ', text)
    text = re.sub(r'ã€‰(?!\s)', 'ã€‰ ', text)
    return text

def parse_html_description(html_desc, session):
    """HTML ì„¤ëª…ì„ íŒŒì‹±í•˜ì—¬ ë‰´ìŠ¤ í•­ëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    soup = BeautifulSoup(html_desc, 'html.parser')
    items = soup.find_all('li')

    news_items = []
    full_content_link = ""
    for item in items:
        if 'Google ë‰´ìŠ¤ì—ì„œ ì „ì²´ ì½˜í…ì¸  ë³´ê¸°' in item.text or 'View Full Coverage on Google News' in item.text:
            full_content_link_match = item.find('a')
            if full_content_link_match:
                full_content_link = full_content_link_match['href']
            continue

        title_match = item.find('a')
        press_match = item.find('font', color="#6f6f6f")
        if title_match and press_match:
            google_link = title_match['href']
            link = get_original_url(google_link, session)
            title_text = replace_brackets(title_match.text)
            press_name = press_match.text
            news_item = f"- [{title_text}](<{link}>) | {press_name}"
            news_items.append(news_item)

    news_string = '\n'.join(news_items)
    if full_content_link:
        news_string += f"â–¶ï¸ [Google ë‰´ìŠ¤ì—ì„œ ì „ì²´ ì½˜í…ì¸  ë³´ê¸°]({full_content_link})"

    return news_string

def extract_news_items(description, session):
    """HTML ì„¤ëª…ì—ì„œ ë‰´ìŠ¤ í•­ëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    soup = BeautifulSoup(description, 'html.parser')
    news_items = []
    for li in soup.find_all('li'):
        a_tag = li.find('a')
        if a_tag:
            title = replace_brackets(a_tag.text)
            google_link = a_tag['href']
            link = get_original_url(google_link, session)
            press = li.find('font', color="#6f6f6f").text if li.find('font', color="#6f6f6f") else ""
            news_items.append({"title": title, "link": link, "press": press})
    return news_items

def parse_rss_date(pub_date):
    """RSS ë‚ ì§œë¥¼ íŒŒì‹±í•˜ì—¬ í˜•ì‹í™”ëœ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    dt = parser.parse(pub_date)
    dt_kst = dt.astimezone(gettz('Asia/Seoul'))
    return dt_kst.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')

def send_discord_message(webhook_url, message, avatar_url=None, username=None):
    """Discord ì›¹í›…ì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤."""
    payload = {"content": message}
    
    # ì•„ë°”íƒ€ URLì´ ì œê³µë˜ê³  ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ payloadì— ì¶”ê°€
    if avatar_url and avatar_url.strip():
        payload["avatar_url"] = avatar_url
    
    # ì‚¬ìš©ì ì´ë¦„ì´ ì œê³µë˜ê³  ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ payloadì— ì¶”ê°€
    if username and username.strip():
        payload["username"] = username
    
    headers = {"Content-Type": "application/json"}
    response = requests.post(webhook_url, json=payload, headers=headers)
    if response.status_code != 204:
        logging.error(f"Discordì— ë©”ì‹œì§€ë¥¼ ê²Œì‹œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: {response.status_code}")
        logging.error(response.text)
    else:
        logging.info("Discordì— ë©”ì‹œì§€ ê²Œì‹œ ì™„ë£Œ")
    time.sleep(3)

def apply_advanced_filter(title, description, advanced_filter):
    """ê³ ê¸‰ ê²€ìƒ‰ í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ê²Œì‹œë¬¼ì„ ì „ì†¡í• ì§€ ê²°ì •í•©ë‹ˆë‹¤."""
    if not advanced_filter:
        return True

    text_to_check = (title + ' ' + description).lower()

    # ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê³ ê¸‰ ê²€ìƒ‰ ì¿¼ë¦¬ íŒŒì‹±
    terms = re.findall(r'([+-]?)(?:"([^"]*)"|\S+)', advanced_filter)

    for prefix, term in terms:
        term = term.lower() if term else prefix.lower()
        if prefix == '+' or not prefix:  # í¬í•¨í•´ì•¼ í•˜ëŠ” ë‹¨ì–´
            if term not in text_to_check:
                return False
        elif prefix == '-':  # ì œì™¸í•´ì•¼ í•˜ëŠ” ë‹¨ì–´ ë˜ëŠ” êµ¬ë¬¸
            # ì—¬ëŸ¬ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ì œì™¸ êµ¬ë¬¸ ì²˜ë¦¬
            exclude_terms = term.split()
            if len(exclude_terms) > 1:
                if ' '.join(exclude_terms) in text_to_check:
                    return False
            else:
                if term in text_to_check:
                    return False

    return True

def parse_date_filter(filter_string):
    """ë‚ ì§œ í•„í„° ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ê¸°ì¤€ ë‚ ì§œì™€ ê¸°ê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    since_date = None
    until_date = None
    past_date = None

    # since ë˜ëŠ” until íŒŒì‹±
    since_match = re.search(r'since:(\d{4}-\d{2}-\d{2})', filter_string)
    until_match = re.search(r'until:(\d{4}-\d{2}-\d{2})', filter_string)
    
    if since_match:
        since_date = datetime.strptime(since_match.group(1), '%Y-%m-%d')
    elif until_match:
        until_date = datetime.strptime(until_match.group(1), '%Y-%m-%d')

    # past íŒŒì‹±
    past_match = re.search(r'past:(\d+)([hdmy])', filter_string)
    if past_match:
        value = int(past_match.group(1))
        unit = past_match.group(2)
        now = datetime.now()
        if unit == 'h':
            past_date = now - timedelta(hours=value)
        elif unit == 'd':
            past_date = now - timedelta(days=value)
        elif unit == 'm':
            past_date = now - timedelta(days=value*30)  # ê·¼ì‚¬ê°’ ì‚¬ìš©
        elif unit == 'y':
            past_date = now - timedelta(days=value*365)  # ê·¼ì‚¬ê°’ ì‚¬ìš©

    return since_date, until_date, past_date

def is_within_date_range(pub_date, since_date, until_date, past_date):
    """ì£¼ì–´ì§„ ë‚ ì§œê°€ í•„í„° ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    pub_datetime = parser.parse(pub_date)
    
    if past_date:
        return pub_datetime >= past_date
    
    if since_date:
        return pub_datetime >= since_date
    if until_date:
        return pub_datetime <= until_date
    
    return True

def extract_topic_id(url):
    """RSS URLì—ì„œ í† í”½ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    parsed_url = urlparse(url)
    path_parts = parsed_url.path.split('/')
    if 'topics' in path_parts:
        return path_parts[path_parts.index('topics') + 1]
    return None

def get_topic_category(keyword, lang='en'):
    """í† í”½ í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    categories = {
        "headlines": {
            "en": "Headlines news",
            "ko": "í—¤ë“œë¼ì¸ ë‰´ìŠ¤",
            "zh": "å¤´æ¡æ–°é—»",
            "ja": "ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Schlagzeilen",
            "fr": "ActualitÃ©s Ã  la une",
            "es": "Titulares",
            "pt": "NotÃ­cias principais",
            "it": "Notizie in primo piano",
            "nl": "Hoofdnieuws",
            "sv": "Nyheter i fokus",
            "ar": "Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø£Ø®Ø¨Ø§Ø±",
            "ru": "Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["headlines", "korea", "world", "politics"]
        },
        "entertainment": {
            "en": "Entertainment news",
            "ko": "ì—°ì˜ˆ ë‰´ìŠ¤",
            "zh": "å¨±ä¹æ–°é—»",
            "ja": "èŠ¸èƒ½é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Unterhaltung",
            "fr": "Actus divertissements",
            "es": "Noticias sobre espectÃ¡culos",
            "pt": "NotÃ­cias de entretenimento",
            "it": "Notizie di intrattenimento",
            "nl": "Entertainmentnieuws",
            "sv": "UnderhÃ¥llningsnyheter",
            "ar": "Ø£Ø®Ø¨Ø§Ø± ØªØ±ÙÙŠÙ‡ÙŠØ©",
            "ru": "Ğ Ğ°Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["entertainment", "celebrity", "tv", "music", "movies", "theater"]
        },
        "sports": {
            "en": "Sports news",
            "ko": "ìŠ¤í¬ì¸  ë‰´ìŠ¤",
            "zh": "ä½“è‚²æ–°é—»",
            "ja": "ã‚¹ãƒãƒ¼ãƒ„é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Sport",
            "fr": "Actus sportives",
            "es": "Noticias sobre deportes",
            "pt": "NotÃ­cias de esportes",
            "it": "Notizie sportive",
            "nl": "Sportnieuws",
            "sv": "Sportnyheter",
            "ar": "Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©",
            "ru": "Ğ¡Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["sports", "soccer", "cycling", "motorsports", "tennis", "martial_arts", 
                         "basketball", "baseball", "american_football", "sports_betting", 
                         "water_sports", "hockey", "golf", "cricket", "rugby"]
        },
        "business": {
            "en": "Business news",
            "ko": "ë¹„ì¦ˆë‹ˆìŠ¤ ë‰´ìŠ¤",
            "zh": "è´¢ç»æ–°é—»",
            "ja": "ãƒ“ã‚¸ãƒã‚¹é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Wirtschaftsmeldungen",
            "fr": "Actus Ã©conomiques",
            "es": "Noticias de negocios",
            "pt": "NotÃ­cias de negÃ³cios",
            "it": "Notizie economiche",
            "nl": "Zakennieuws",
            "sv": "Ekonominyheter",
            "ar": "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø£Ø¹Ù…Ø§Ù„",
            "ru": "Ğ‘Ğ¸Ğ·Ğ½ĞµÑ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["business", "economy", "personal_finance", "finance", "digital_currency"]
        },
        "technology": {
            "en": "Technology news",
            "ko": "ê¸°ìˆ  ë‰´ìŠ¤",
            "zh": "ç§‘æŠ€æ–°é—»",
            "ja": "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Technologie",
            "fr": "Actus technologie",
            "es": "Noticias de tecnologÃ­a",
            "pt": "NotÃ­cias de tecnologia",
            "it": "Notizie di tecnologia",
            "nl": "Technologienieuws",
            "sv": "Teknologinyheter",
            "ar": "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§",
            "ru": "Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["technology", "mobile", "energy", "games", "internet_security", 
                         "electronics", "virtual_reality", "robotics"]
        },
        "health": {
            "en": "Health news",
            "ko": "ê±´ê°• ë‰´ìŠ¤",
            "zh": "å¥åº·æ–°é—»",
            "ja": "å¥åº·é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Gesundheit",
            "fr": "Actus santÃ©",
            "es": "Noticias sobre salud",
            "pt": "NotÃ­cias de saÃºde",
            "it": "Notizie di salute",
            "nl": "Gezondheidsnieuws",
            "sv": "HÃ¤lsonews",
            "ar": "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØµØ­Ø©",
            "ru": "ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ",
            "keywords": ["health", "nutrition", "public_health", "mental_health", "medicine"]
        },
        "science": {
            "en": "Science news",
            "ko": "ê³¼í•™ ë‰´ìŠ¤",
            "zh": "ç§‘å­¦æ–°é—»",
            "ja": "ç§‘å­¦é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Wissenschaft",
            "fr": "Actus sciences",
            "es": "Noticias de ciencia",
            "pt": "NotÃ­cias de ciÃªncia",
            "it": "Notizie di scienza",
            "nl": "Wetenschapsnieuws",
            "sv": "Vetenskapsnyheter",
            "ar": "Ø£Ø®Ø¨Ø§Ø± Ø¹Ù„Ù…ÙŠØ©",
            "ru": "ĞĞ°ÑƒÑ‡Ğ½Ñ‹Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["science", "space", "wildlife", "environment", "neuroscience", 
                         "physics", "geography", "paleontology", "social_science"]
        },
        "education": {
            "en": "Education news",
            "ko": "êµìœ¡ ë‰´ìŠ¤",
            "zh": "æ•™è‚²æ–°é—»",
            "ja": "æ•™è‚²é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Bildung",
            "fr": "Actus enseignement",
            "es": "Noticias sobre educaciÃ³n",
            "pt": "NotÃ­cias de educaÃ§Ã£o",
            "it": "Notizie di istruzione",
            "nl": "Onderwijsnieuws",
            "sv": "Utbildningsnyheter",
            "ar": "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªØ¹Ù„ÙŠÙ…",
            "ru": "ĞĞ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸",
            "keywords": ["education", "job_market", "online_education", "higher_education"]
        },
        "lifestyle": {
            "en": "Lifestyle news",
            "ko": "ë¼ì´í”„ìŠ¤íƒ€ì¼ ë‰´ìŠ¤",
            "zh": "ç”Ÿæ´»æ—¶å°šæ–°é—»",
            "ja": "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«é–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "de": "Nachrichten aus dem Bereich Lifestyle",
            "fr": "Actus mode de vie",
            "es": "Noticias de estilo de vida",
            "pt": "NotÃ­cias de estilo de vida",
            "it": "Notizie di lifestyle",
            "nl": "Lifestyle nieuws",
            "sv": "Livsstilsnyheter",
            "ar": "Ø£Ø®Ø¨Ø§Ø± Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø­ÙŠØ§Ø©",
            "ru": "ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ° Ğ¶Ğ¸Ğ·Ğ½Ğ¸",
            "keywords": ["lifestyle", "automotive", "art_design", "beauty", "food", "travel", 
                         "shopping", "home", "outdoor", "fashion"]
        }
    }
    
    lang_key = 'ko' if lang.startswith('ko') else 'en'
    topic_map_lang_key = 'ko-KR' if lang.startswith('ko') else 'en-US'
    
    logging.info(f"get_topic_category called with keyword: {keyword}, lang: {lang}")
    
    for category, data in categories.items():
        if keyword in data["keywords"]:
            return data[lang_key]
    
    # TOPIC_MAPì—ì„œ IDë¡œ ê²€ìƒ‰
    for topic, topic_data in TOPIC_MAP.items():
        if keyword == topic or keyword == topic_data[topic_map_lang_key][1]:
            # topicì— í•´ë‹¹í•˜ëŠ” ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
            for category, data in categories.items():
                if topic in data["keywords"]:
                    return data[lang_key]
    
    logging.warning(f"No matching category found for keyword: {keyword}")
    
    return "ê¸°íƒ€ ë‰´ìŠ¤" if lang_key == 'ko' else "Other News"

def get_topic_display_name(keyword_or_id, lang):
    """í† í”½ í‚¤ì›Œë“œ ë˜ëŠ” IDì— í•´ë‹¹í•˜ëŠ” í‘œì‹œ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    lang_key = 'ko-KR' if lang.startswith('ko') else 'en-US'
    for topic, data in TOPIC_MAP.items():
        if keyword_or_id == topic or keyword_or_id == data[lang_key][1]:
            return data[lang_key][0]
    return keyword_or_id  # ì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ìœ¼ë©´ ì›ë˜ ê°’ì„ ë°˜í™˜

def get_country_emoji(country_code):
    """êµ­ê°€ ì½”ë“œë¥¼ ìœ ë‹ˆì½”ë“œ í”Œë˜ê·¸ ì´ëª¨ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if len(country_code) != 2:
        return ''
    return chr(ord(country_code[0].upper()) + 127397) + chr(ord(country_code[1].upper()) + 127397)

def parse_topic_params(url):
    """URLì—ì„œ ì–¸ì–´, êµ­ê°€ ì½”ë“œ, ceid ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    params = urlparse(url).query
    parsed_params = parse_qs(params)
    hl = parsed_params.get('hl', ['ko'])[0]
    gl = parsed_params.get('gl', ['KR'])[0]
    ceid = parsed_params.get('ceid', [f'{gl}:{hl}'])[0]
    return hl, gl, ceid

def is_korean_params(params):
    """íŒŒë¼ë¯¸í„°ê°€ í•œêµ­ì–´ ì„¤ì •ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return 'hl=ko' in params and 'gl=KR' in params and 'ceid=KR%3Ako' in params

def main():
    init_db(reset=INITIALIZE_TOPIC)

    session = requests.Session()

    since_date, until_date, past_date = parse_date_filter(DATE_FILTER_TOPIC)

    # ë¡œê¹… ì¶”ê°€
    logging.info(f"TOPIC_MODE: {TOPIC_MODE}")
    logging.info(f"TOPIC_KEYWORD: {TOPIC_KEYWORD}")

    if TOPIC_MODE:
        try:
            topic_id = TOPIC_MAP[TOPIC_KEYWORD]['ko-KR'][1]  # 'ko-KR' ë˜ëŠ” 'en-US' ì„ íƒ
        except KeyError:
            logging.error(f"Invalid TOPIC_KEYWORD: {TOPIC_KEYWORD}")
            return
        rss_url = f"https://news.google.com/rss/topics/{topic_id}"
        if TOPIC_PARAMS:
            rss_url += TOPIC_PARAMS
    else:
        rss_url = RSS_URL_TOPIC
        topic_id = extract_topic_id(rss_url)

    logging.info(f"RSS URL: {rss_url}")
    logging.info(f"Topic ID: {topic_id}")

    hl, gl, ceid = parse_topic_params(rss_url)
    logging.info(f"Parsed parameters - hl: {hl}, gl: {gl}, ceid: {ceid}")

    rss_data = fetch_rss_feed(rss_url)
    if rss_data is None:
        logging.error("RSS ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    root = ET.fromstring(rss_data)

    news_items = root.findall('.//item')
    if INITIALIZE_TOPIC:
        news_items = sorted(news_items, key=lambda item: parser.parse(item.find('pubDate').text))
    else:
        news_items = list(reversed(news_items))

    for item in news_items:
        guid = item.find('guid').text

        # ì´ˆê¸°í™” ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¤‘ë³µ ê²€ì‚¬
        if not INITIALIZE_TOPIC and is_guid_posted(guid):
            continue

        title = replace_brackets(item.find('title').text)
        google_link = item.find('link').text
        link = get_original_url(google_link, session)
        pub_date = item.find('pubDate').text
        description_html = item.find('description').text
        
        formatted_date = parse_rss_date(pub_date)

        # ë‚ ì§œ í•„í„° ì ìš©
        if not is_within_date_range(pub_date, since_date, until_date, past_date):
            logging.info(f"ë‚ ì§œ í•„í„°ì— ì˜í•´ ê±´ë„ˆë›°ì–´ì§„ ë‰´ìŠ¤: {title}")
            continue

        related_news = extract_news_items(description_html, session)
        related_news_json = json.dumps(related_news, ensure_ascii=False)

        description = parse_html_description(description_html, session)

        # ê³ ê¸‰ ê²€ìƒ‰ í•„í„° ì ìš©
        if not apply_advanced_filter(title, description, ADVANCED_FILTER_TOPIC):
            logging.info(f"ê³ ê¸‰ ê²€ìƒ‰ í•„í„°ì— ì˜í•´ ê±´ë„ˆë›°ì–´ì§„ ë‰´ìŠ¤: {title}")
            continue

        news_prefix = get_news_prefix(hl)
        
        if TOPIC_MODE or topic_id:
            category_input = TOPIC_KEYWORD if TOPIC_MODE else topic_id
            logging.info(f"Calling get_topic_category with: {category_input}, {hl}")
            category = get_topic_category(category_input, hl)
            topic_name = get_topic_display_name(category_input, hl)
        else:
            category = "ì¼ë°˜ ë‰´ìŠ¤" if hl.startswith('ko') else "General news"
            topic_name = "RSS í”¼ë“œ" if hl.startswith('ko') else "RSS Feed"

        country_emoji = get_country_emoji(gl)

        discord_message = f"`{news_prefix} - {category} - {topic_name} {country_emoji}`\n**{title}**\n{link}"
        if description:
            discord_message += f"\n>>> {description}\n\n"
        else:
            discord_message += "\n\n"
        discord_message += f"ğŸ“… {formatted_date}"

        logging.info(f"Sending message to Discord: {discord_message[:100]}...")  # ë¡œê·¸ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ

        send_discord_message(
            DISCORD_WEBHOOK_TOPIC,
            discord_message,
            avatar_url=DISCORD_AVATAR_TOPIC,
            username=DISCORD_USERNAME_TOPIC
        )

        save_news_item(pub_date, guid, title, link, TOPIC_KEYWORD if TOPIC_MODE else "general", related_news_json)

        if not INITIALIZE_TOPIC:
            time.sleep(3)

if __name__ == "__main__":
    try:
        check_env_variables()
        main()
    except Exception as e:
        logging.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        sys.exit(1)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹„ì •ìƒ ì¢…ë£Œ
    else:
        logging.info("í”„ë¡œê·¸ë¨ ì •ìƒ ì¢…ë£Œ")